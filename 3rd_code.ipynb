{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b4cdaf-772f-48ad-a7e4-a14b9d99b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#training and testing the LcgNetV with LMMSE algorithm\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2b028-da2a-4d89-8d67-fdabff9aee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "def generate_data(B, K, N, snr_low, snr_high, H_org):\n",
    "    x_ = np.sign(np.random.rand(B, K) - 0.5)\n",
    "    y_ = np.zeros([B, N])\n",
    "    w = np.random.randn(B, N)\n",
    "    Hy_ = x_ * 0\n",
    "    H_ = np.zeros([B, N, K])\n",
    "    HH_ = np.zeros([B, K, K])\n",
    "    SNR_ = np.zeros([B])\n",
    "    x_ind = np.zeros([B, K, 2])\n",
    "    for i in range(B):\n",
    "        for ii in range(K):\n",
    "            if x_[i][ii] == 1:\n",
    "                x_ind[i][ii][0] = 1\n",
    "            if x_[i][ii] == -1:\n",
    "                x_ind[i][ii][1] = 1\n",
    "    for i in range(B):\n",
    "        SNR = np.random.uniform(low=snr_low, high=snr_high)\n",
    "        H = H_org\n",
    "        tmp_snr = (H.T.dot(H)).trace() / K\n",
    "       # H = H / np.sqrt(tmp_snr) * np.sqrt(SNR)\n",
    "        H_[i, :, :] = H\n",
    "        y_[i, :] = (H.dot(x_[i, :]) + w[i, :] * np.sqrt(tmp_snr) / np.sqrt(SNR))\n",
    "        Hy_[i, :] = H.T.dot(y_[i, :])\n",
    "        HH_[i, :, :] = H.T.dot(H_[i, :, :])\n",
    "        SNR_[i] = SNR\n",
    "    return y_, H_, Hy_, HH_, x_, SNR_, x_ind,tmp_snr\n",
    "\n",
    "\n",
    "# Parameters\n",
    "B = 1000 # Batch size\n",
    "K = 12   # Number of users\n",
    "N = 12    # Number of antennas\n",
    "T = 8 # Total layers (iterations)\n",
    "H_org = np.random.randn(N, K)\n",
    "frobenius_norm = np.linalg.norm(H_org, 'fro')  # Frobenius norm of the matrix\n",
    "H_org = H_org / frobenius_norm\n",
    "\n",
    "snr_test = [13,12,11,10,9,8]  # SNR values for testing\n",
    "\n",
    "# Define Learning Rates\n",
    "trinit = 0.001  # Initial learning rate\n",
    "#refinements = [1.0, 0.5, 0.1, 0.01]\n",
    "refinements = [1.0,0.5,0.1]  # Refinement factors for fine-tuning\n",
    "fine_tune_lrs = [trinit * refinement for refinement in refinements]\n",
    "\n",
    "# Placeholders\n",
    "y = tf.placeholder(tf.float32, shape=(None, N), name='y')\n",
    "H = tf.placeholder(tf.float32, shape=(None, N, K), name='H')\n",
    "Hy = tf.placeholder(tf.float32, shape=(None, K), name='Hy')\n",
    "HH = tf.placeholder(tf.float32, shape=(None, K, K), name='HH')\n",
    "x_true = tf.placeholder(tf.float32, shape=(None, K), name='x_true')\n",
    "sigma2 = tf.placeholder(tf.float32, shape=(), name='noise_variance')  # Noise variance placeholder\n",
    "\n",
    "# Identity matrix\n",
    "I_Nt = tf.eye(K, dtype=tf.float32)\n",
    "\n",
    "# Calculate A_rm and b_rm\n",
    "A_rm = HH + sigma2 * I_Nt  # A_rm = H^T H + Ïƒ^2 I\n",
    "b_rm = Hy  # b_rm = H^T y\n",
    "\n",
    "# Initialize trainable parameters\n",
    "alpha = [tf.Variable(tf.zeros([K]), name=f'alpha_{t}') for t in range(T)]\n",
    "beta = [tf.Variable(tf.zeros([K]), name=f'beta_{t}') for t in range(T)]\n",
    "\n",
    "# Initialize CG-based iterative refinement\n",
    "s_hat = tf.zeros_like(x_true, name='s_hat_init')\n",
    "r = b_rm - tf.squeeze(tf.matmul(A_rm, tf.expand_dims(s_hat, -1)), axis=-1)  # r^0_rm = b_rm\n",
    "d = tf.identity(r)  # d^0_rm = r^0_rm\n",
    "states = []\n",
    "\n",
    "for t in range(T):\n",
    "    # Update s_hat (estimate of x)\n",
    "    s_hat = s_hat + tf.multiply(alpha[t],d)# s^(i+1)_rm\n",
    "    r = r - tf.multiply(alpha[t], tf.squeeze(tf.matmul(A_rm, tf.expand_dims(d, -1)), axis=-1))  # r^(i+1)_rm\n",
    "    d = r +tf.multiply(beta[t],d) # d^(i+1)_rm\n",
    "    states.append(s_hat)\n",
    "\n",
    "s_hat_final = states[-1]\n",
    "\n",
    "# Loss and NMSE\n",
    "loss = tf.reduce_mean(tf.square(s_hat_final - x_true))\n",
    "nmse = tf.reduce_mean(tf.square(s_hat_final - x_true)) / tf.reduce_mean(tf.square(x_true))\n",
    "\n",
    "# Training Operations for each layer\n",
    "train_ops = [tf.train.AdamOptimizer(trinit).minimize(loss, var_list=[alpha[t], beta[t]]) for t in range(T)]\n",
    "\n",
    "# Fine-Tuning Operations\n",
    "fine_tune_ops = {\n",
    "    lr: tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "    for lr in fine_tune_lrs\n",
    "}\n",
    "\n",
    "# Validation\n",
    "def validate_model(sess, y_val, H_val, Hy_val, HH_val, x_val, sigma2_val):\n",
    "    feed_dict = {\n",
    "        y: y_val,\n",
    "        H: H_val,\n",
    "        Hy: Hy_val,\n",
    "        HH: HH_val,\n",
    "        x_true: x_val,\n",
    "        sigma2: sigma2_val\n",
    "    }\n",
    "    return sess.run(nmse, feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "# Training with Early Stopping\n",
    "def train_for_snr(sess, snr, train_ops, fine_tune_ops, y, H, Hy, HH, x_true, sigma2, patience=3):\n",
    "    print(f\"Training and Fine-tuning for SNR = {snr[0]} dB...\")\n",
    "\n",
    "    for t in range(T):\n",
    "        print(f\"Training Layer {t+1}/{T} for SNR = {snr[0]} dB...\")\n",
    "\n",
    "        y_train, H_train, Hy_train, HH_train, x_train, _, _,tmp_snr = generate_data(B, K, N, *snr, H_org)\n",
    "        y_val, H_val, Hy_val, HH_val, x_val, _, _ ,tmp_snr= generate_data(B, K, N, *snr, H_org)\n",
    "\n",
    "        sigma2_val = tmp_snr/snr[0]\n",
    "\n",
    "        best_val_nmse = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(100):  # Max epochs\n",
    "            feed_dict = {\n",
    "                y: y_train,\n",
    "                H: H_train,\n",
    "                Hy: Hy_train,\n",
    "                HH: HH_train,\n",
    "                x_true: x_train,\n",
    "                sigma2: sigma2_val\n",
    "            }\n",
    "            sess.run(train_ops[t], feed_dict=feed_dict)\n",
    "\n",
    "            val_nmse = validate_model(sess, y_val, H_val, Hy_val, HH_val, x_val, sigma2_val)\n",
    "            print(f\"Layer {t+1}, Epoch {epoch+1}: Validation NMSE = {val_nmse:.6f}\")\n",
    "\n",
    "            if val_nmse < best_val_nmse:\n",
    "                best_val_nmse = val_nmse\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at Layer {t+1}, Epoch {epoch+1} (Best Validation NMSE = {best_val_nmse:.6f})\")\n",
    "                break\n",
    "\n",
    "        print(f\"Fine-tuning Layers 1 to {t+1} for SNR = {snr[0]} dB...\")\n",
    "        for lr, fine_tune_op in fine_tune_ops.items():\n",
    "            for epoch in range(50):\n",
    "                feed_dict = {\n",
    "                    y: y_train,\n",
    "                    H: H_train,\n",
    "                    Hy: Hy_train,\n",
    "                    HH: HH_train,\n",
    "                    x_true: x_train,\n",
    "                    sigma2: sigma2_val\n",
    "                }\n",
    "                sess.run(fine_tune_op, feed_dict=feed_dict)\n",
    "                val_nmse = validate_model(sess, y_val, H_val, Hy_val, HH_val, x_val, sigma2_val)\n",
    "                print(f\"Fine-tuning LR={lr}, Epoch {epoch+1}: Validation NMSE = {val_nmse:.6f}\")\n",
    "\n",
    "\n",
    "# Add LMMSE Detector\n",
    "def lmmse_detector(H, y, sigma2):\n",
    "\n",
    "    B, N, K = H.shape\n",
    "    I_K = np.eye(K)  # Identity matrix of size K\n",
    "    x_lmmse = np.zeros((B, K))  # Placeholder for LMMSE results\n",
    "\n",
    "    for i in range(B):\n",
    "        H_i = H[i]  # (N, K)\n",
    "        y_i = y[i]  # (N,)\n",
    "        A = H_i.T @ H_i + sigma2 * I_K  # (K, K)\n",
    "        b = H_i.T @ y_i  # (K,)\n",
    "        x_lmmse[i] = np.linalg.solve(A, b)  # Solve Ax = b for LMMSE\n",
    "        \n",
    "    return x_lmmse\n",
    "\n",
    "# Update Testing Function to Include LMMSE\n",
    "def test_model_with_lmmse(sess, snr_value, y_placeholder, H_placeholder, Hy_placeholder, HH_placeholder, x_true_placeholder, s_hat_final_op):\n",
    "    #sigma2_val = 1 /snr_value\n",
    "    y_test, H_test, Hy_test, HH_test, x_test, _, _,tmp_snr = generate_data(1000, K, N, snr_value, snr_value, H_org)\n",
    "    sigma2_val = tmp_snr/snr_value\n",
    "    # Run Iterative Model\n",
    "    feed_dict = {\n",
    "        y_placeholder: y_test,\n",
    "        H_placeholder: H_test,\n",
    "        Hy_placeholder: Hy_test,\n",
    "        HH_placeholder: HH_test,\n",
    "        x_true_placeholder: x_test,\n",
    "        sigma2: sigma2_val\n",
    "    }\n",
    "    x_pred = sess.run(s_hat_final_op, feed_dict=feed_dict)\n",
    "    x_pred_binary = np.sign(x_pred)\n",
    "\n",
    "    # Run LMMSE Detector\n",
    "    x_lmmse = lmmse_detector(H_test, y_test, sigma2_val)\n",
    "    x_lmmse_binary = np.sign(x_lmmse)\n",
    "\n",
    "    # Calculate BER for both models\n",
    "    total_bits = np.prod(x_test.shape)\n",
    "    \n",
    "    ber_iterative = np.sum(x_pred_binary != x_test) / total_bits\n",
    "    ber_lmmse = np.sum(x_lmmse_binary != x_test) / total_bits\n",
    "\n",
    "    return ber_iterative, ber_lmmse\n",
    "\n",
    "# SNR values for progressive training\n",
    "snr_progressive = [30,15,14,11,10,9]  # dB\n",
    "\n",
    "# Main Testing Loop with Progressive Training\n",
    "print(\"\\nTesting the model with progressive training (30 dB to 10 dB) and LMMSE detector...\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Progressive training loop\n",
    "    for snr_db in snr_progressive:\n",
    "        snr = 10**(snr_db / 10.0)  # Convert dB to linear scale\n",
    "        print(f\"\\nTraining for SNR = {snr_db} dB...\")\n",
    "        train_for_snr(sess, (snr,snr), train_ops, fine_tune_ops, y, H, Hy, HH, x_true, sigma2)\n",
    "\n",
    "    # Testing after training\n",
    "    for snr_db in snr_test:\n",
    "        snr = 10**(snr_db / 10.0)  # Convert dB to linear scale\n",
    "        ber_iterative, ber_lmmse = test_model_with_lmmse(sess, snr, y, H, Hy, HH, x_true, s_hat_final)\n",
    "        print(f\"SNR: {snr_db} dB, Iterative Model BER: {ber_iterative:.6f}, LMMSE BER: {ber_lmmse:.6f}\")\n",
    "\n",
    "print(\"Progressive training and testing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
